{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2175269d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import PeftModel, PeftConfig, get_peft_model, LoraConfig\n",
    "import evaluate\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95750c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpt = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e504394d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Define the label maps (Positive --> 1, Negative --> 0)\n",
    "id2label = {0: \"Negative\",\n",
    "            1: \"Positive\"}\n",
    "label2id = {\"Negative\": 0,\n",
    "            \"Positive\": 1}\n",
    "\n",
    "# Classification model from the prescribed model ckpt\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpt,\n",
    "    num_labels = 2,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225649d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset(\"shawhin/imdb-truncated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3406c662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset Structure\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da5dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpt, add_prefix_space = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdd0c7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tokenizer function\n",
    "def tokenize_function(examples):\n",
    "    # Extract text\n",
    "    text = examples['text']\n",
    "\n",
    "    # Now truncate and tokenize the reviewer's text\n",
    "    tokenizer.truncate_side = \"left\"\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a675a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad tokens if none exist\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62db98a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbdb0f4a78e34423a714bc885ea9d85d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'text', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now tokenize datasets -> train and validation\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5080ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data collator\n",
    "dataCollator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3052e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric --> Accuracy\n",
    "accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3aa791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define eval function that we will later use to pass through trainer\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": accuracy.compute(predictions=predictions,\n",
    "                                         references=labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d80a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained model predictions:\n",
      "----------------------------\n",
      "\n",
      "It was good. - Negative\n",
      "Not a fan, don't recommend. - Negative\n",
      "Better than the first one - Negative\n",
      "This is not worth watching even once. - Negative\n",
      "This one is a pass. - Negative\n"
     ]
    }
   ],
   "source": [
    "# Before training the model!\n",
    "\n",
    "text_list = [\n",
    "    \"It was good.\",\n",
    "    \"Not a fan, don't recommend.\",\n",
    "    \"Better than the first one\",\n",
    "    \"This is not worth watching even once.\",\n",
    "    \"This one is a pass.\"\n",
    "]\n",
    "\n",
    "print(\"Untrained model predictions:\")\n",
    "print(\"----------------------------\\n\")\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.argmax(logits)\n",
    "    print(f\"{text} - {id2label[predictions.tolist()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "313d9234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LoRA\n",
    "peft_config = LoraConfig(task_type=\"SEQ_CLS\",       # Sequence Classification\n",
    "                        r=4,                        # Rank\n",
    "                        lora_alpha=32,              # Learning rate\n",
    "                        lora_dropout=0.01,          # Dropout Probability\n",
    "                         target_modules=['q_lin']   # Apply LoRA to query layer\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05fc9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 628,994 || all params: 67,584,004 || trainable%: 0.9306847223789819\n"
     ]
    }
   ],
   "source": [
    "# Update model\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6867ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "lr = 1e-3 \n",
    "batchSize = 4\n",
    "numEpochs = 10\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_checkpt + \"-sentiment-analysis-using-LoRA\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batchSize,\n",
    "    per_device_eval_batch_size=batchSize,\n",
    "    num_train_epochs=numEpochs,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35aa3b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73063d071728407085c2a07b647248af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85b21f77f024a8cb5828bf4abacc66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38284415006637573, 'eval_accuracy': {'accuracy': 0.859}, 'eval_runtime': 32.3703, 'eval_samples_per_second': 30.892, 'eval_steps_per_second': 7.723, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4364, 'grad_norm': 14.797685623168945, 'learning_rate': 0.0008, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca619b09b8e54fb4a9e5d699d53906fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4836050271987915, 'eval_accuracy': {'accuracy': 0.88}, 'eval_runtime': 19.1837, 'eval_samples_per_second': 52.128, 'eval_steps_per_second': 13.032, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94305db6a67a40fda30df1048f3af589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2064400911331177, 'eval_accuracy': {'accuracy': 0.836}, 'eval_runtime': 19.2073, 'eval_samples_per_second': 52.064, 'eval_steps_per_second': 13.016, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2305, 'grad_norm': 0.0324484184384346, 'learning_rate': 0.0006, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768e7ffa7b6c4f5abd9efb6916dcb4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6465535759925842, 'eval_accuracy': {'accuracy': 0.887}, 'eval_runtime': 19.5147, 'eval_samples_per_second': 51.243, 'eval_steps_per_second': 12.811, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5414ca3cc7a64296a7f94fe1f5109804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7836781144142151, 'eval_accuracy': {'accuracy': 0.892}, 'eval_runtime': 19.0922, 'eval_samples_per_second': 52.377, 'eval_steps_per_second': 13.094, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0653, 'grad_norm': 0.00022772687952965498, 'learning_rate': 0.0004, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdc317be5b0e470fa613365d47192f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8337900638580322, 'eval_accuracy': {'accuracy': 0.889}, 'eval_runtime': 19.3765, 'eval_samples_per_second': 51.609, 'eval_steps_per_second': 12.902, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8255a5d32bc544cb8fe17ebc6024eace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9208342432975769, 'eval_accuracy': {'accuracy': 0.887}, 'eval_runtime': 19.1313, 'eval_samples_per_second': 52.27, 'eval_steps_per_second': 13.068, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0154, 'grad_norm': 0.0009204890229739249, 'learning_rate': 0.0002, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69befab9fd3641e7a5a92fdc45054d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0305984020233154, 'eval_accuracy': {'accuracy': 0.888}, 'eval_runtime': 19.3171, 'eval_samples_per_second': 51.767, 'eval_steps_per_second': 12.942, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c5f02807264f459b39c6524144e819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0186481475830078, 'eval_accuracy': {'accuracy': 0.885}, 'eval_runtime': 19.1585, 'eval_samples_per_second': 52.196, 'eval_steps_per_second': 13.049, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0079, 'grad_norm': 5.9334747675166e-06, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0882e223b0d47efb80b5f288a2ec405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.040765404701233, 'eval_accuracy': {'accuracy': 0.885}, 'eval_runtime': 19.456, 'eval_samples_per_second': 51.398, 'eval_steps_per_second': 12.85, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/AshishR_T/miniconda3/envs/llmFromScratch/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 722.1403, 'train_samples_per_second': 13.848, 'train_steps_per_second': 3.462, 'train_loss': 0.15112618370056152, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2500, training_loss=0.15112618370056152, metrics={'train_runtime': 722.1403, 'train_samples_per_second': 13.848, 'train_steps_per_second': 3.462, 'train_loss': 0.15112618370056152, 'epoch': 10.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_dataset['train'],\n",
    "    eval_dataset = tokenized_dataset['validation'],\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = dataCollator,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9a054fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model predictions:\n",
      "----------------------------\n",
      "\n",
      "It was good. - Positive\n",
      "Not a fan, don't recommend. - Negative\n",
      "Better than the first one - Positive\n",
      "This is not worth watching even once. - Negative\n",
      "This one is a pass. - Negative\n"
     ]
    }
   ],
   "source": [
    "model.to('mps')\n",
    "\n",
    "print(\"Trained model predictions:\")\n",
    "print(\"----------------------------\\n\")\n",
    "\n",
    "for text in text_list:\n",
    "    inputs = tokenizer.encode(text, return_tensors=\"pt\").to(\"mps\")\n",
    "    logits = model(inputs).logits\n",
    "    predictions = torch.max(logits, 1).indices\n",
    "    print(f\"{text} - {id2label[predictions.tolist()[0]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmFromScratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
